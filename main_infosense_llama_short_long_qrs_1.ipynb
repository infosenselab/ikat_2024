{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IKAT 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyserini.search import LuceneSearcher\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from src.utils import use_llama, prepare_output_for_json, join_and_cap_passages, get_true_ptkbs, has_qrels_for_conversation, combine_performance_metrics, combine_hits, full_evaluations_join, run_generate_run, measure_intrarun_ranking_performance, check_quick_retrieval_success, extract_evaluations, select_turns_by_prefix, run_trec_eval, extract_relevant_passages, passage_neural_retrieval\n",
    "\n",
    "\n",
    "import settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_ptkb_ranker(model, tokenizer, query, ptkb):\n",
    "    \n",
    "    # save all the prints to a text file for tracking system progress\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write('\\n\\n### Available PTKB statements are:\\n')\n",
    "        for key in sorted(ptkb.keys(), key=int):\n",
    "            f.write(f\"{key}. {ptkb[key]}\\n\")\n",
    "    \n",
    "\n",
    "    # get response\n",
    "    relevant_ptkb_statements_ids = use_llama(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        system_message_content=\"\"\"\n",
    "        You are an Assistant that returns ONLY console output, without any additional words, niceties or verbosity of any kind. \n",
    "        \n",
    "        # Instructions \n",
    "        \n",
    "        // You are instructed to return a JSON and you are to return only the JSON object and nothing else. \n",
    "        // You have been assigned a classification task. The user will provide you with a conversation ending with a latest user reply and a list of statements. \n",
    "        // YOU MUST CONSIDER WHICH STATEMENTS ARE THE MOST RELEVANT TO ANSWER THE LATEST USER REPLY.\n",
    "        // Your job is to remove the statements are irrelevant to the text query. Statements that are only somewhat related should not be eliminated. Only eliminate if not at all related.\n",
    "        // Then, assign scores of how related the statement is to the query with numbers between 1 and 0, where 1 is the highest. \n",
    "        // I REPEAT: ONE IS THE HIGHEST AND ZERO IS THE LOWEST. \n",
    "        // You can only return statements from the provided list. I REPEAT: You can only return statements from the provided list.\n",
    "        // You will return only a JSON of the `id` and `score`. Nothing else. \n",
    "        // You must make sure the IDs are returned as strings, regardless that they are integers. \n",
    "        // Don't be overly stringent with your definition or relevant. Loosely related is enough. \n",
    "        // Do not include statements that are irrelevant to the text passage. I REPEAT: DO NOT include statements if they are not related at all. \n",
    "        \n",
    "        # Examples \n",
    "                \n",
    "        Input:\n",
    "        The Latest User Reply is \"Can you tell me the best place to find Pokemon?\" and the statements are \n",
    "        {'1': \"I'm amazed at the fact that the human body has 206 bones.\", \n",
    "        '2': \"I started my journey as a Pokémon trainers at the age of ten.\", \n",
    "        '3': \"My favorite cuisine is Italian, especially pizza and pasta.\", \n",
    "        '4': \"I enjoy hiking in the mountains during my free time.\", \n",
    "        '5': \"I love the Eiffel Tower as it is one of the most famous landmarks in Paris.\", \n",
    "        '6': \"I believe Pikachu is the most iconic and recognizable Pokémon in the world.\"}       \n",
    "        \n",
    "        Required Output: \n",
    "        `[{\"id\": \"2\", \"score\": 0.98}, {\"id\": \"6\", \"score\": 0.81}]`\n",
    "        \n",
    "\n",
    "        Input:\n",
    "        The Latest User Reply is \"I wish to get facts on the importance of education?\" and the statements are\n",
    "        {\n",
    "        '1': \"I believe that education is crucial for personal development.\",\n",
    "        '2': \"I enjoy hiking in the mountains during my free time.\",\n",
    "        '3': \"In my opinion, continuous learning is important for staying relevant in any field.\",\n",
    "        '4': \"I think education should be accessible to everyone, regardless of their background.\",\n",
    "        '5': \"My favorite cuisine is Italian, especially pizza and pasta.\",\n",
    "        '6': \"I feel that a strong educational foundation is essential for success in life.\"\n",
    "        }\n",
    "        \n",
    "        Required Output:\n",
    "        `[{\"id\": \"1\", \"score\": 1.0}, {\"id\": \"3\", \"score\": 0.85}, {\"id\": \"4\", \"score\": 0.75}, {\"id\": \"6\", \"score\": 0.7}]`\n",
    "\n",
    "        Input:\n",
    "        The Latest User Reply is \"What are your favorite foods?\" and the statements are\n",
    "        {\n",
    "        '1': \"I love Italian cuisine, especially pasta.\",\n",
    "        '2': \"I have a cat named Whiskers.\",\n",
    "        '3': \"Chocolate cake is my go-to dessert.\",\n",
    "        '4': \"I enjoy swimming in my free time.\",\n",
    "        '5': \"Spicy foods are a favorite of mine.\",\n",
    "        '6': \"I recently visited Japan and loved the sushi there.\"\n",
    "        }\n",
    "        \n",
    "        Required Output:\n",
    "        `[{\"id\": \"1\", \"score\": 0.99}, {\"id\": \"3\", \"score\": 0.85}, {\"id\": \"5\", \"score\": 0.7}, {\"id\": \"6\", \"score\": 0.4}]`\n",
    "       \n",
    "       \n",
    "       Thank you for the clarification! Here’s a new version of the example with only relevant statements about Paris and the rest being random personal facts starting with \"I...\".\n",
    "\n",
    "        ### Input:  \n",
    "        The Latest User Reply is \"Can you share some insights on traveling to Paris?\" and the statements are:  \n",
    "        {\n",
    "        '1': \"I love visiting famous landmarks like the Eiffel Tower in Paris.\",  \n",
    "        '2': \"I enjoy painting landscapes during my free time.\",  \n",
    "        '3': \"The Louvre is one of the most visited museums in Paris.\",  \n",
    "        '4': \"I recently adopted a puppy named Max.\",  \n",
    "        '5': \"I have been learning French for the past two years.\",  \n",
    "        '6': \"I think Paris is one of the most beautiful cities in the world.\"  \n",
    "        }\n",
    "\n",
    "        ### Required Output:  \n",
    "        `[{\"id\": \"1\", \"score\": 1.0}, {\"id\": \"3\", \"score\": 0.9}, {\"id\": \"6\", \"score\": 0.85}]`\n",
    "        \n",
    "        SCORE OF ZERO ARE NOT ALLOWED.\n",
    "\n",
    "        \n",
    "        \"\"\",\n",
    "        user_message_content=f\"\"\"The text query is \"{query}\" and the statements are {ptkb}\"\"\")\n",
    "        # NOTE: The examples above are LLM generated.\n",
    "    \n",
    "  # save all the prints to a text file for tracking system progress\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write('\\n\\n### Raw output\\n')\n",
    "        f.write(f'{relevant_ptkb_statements_ids}')\n",
    "\n",
    "    # convert from string\n",
    "    relevant_ptkb_statements_ids = ast.literal_eval(relevant_ptkb_statements_ids)\n",
    "\n",
    "\n",
    "    # create a list of dictionaries with the relevant PTKB statements, including the score\n",
    "    relevant_ptkb_statements = [\n",
    "        {'id': item['id'], 'statement': ptkb[item['id']], 'score': item['score']}\n",
    "        for item in relevant_ptkb_statements_ids\n",
    "    ]\n",
    "    \n",
    "    # sort the list of dictionaries by score, from highest to lowest\n",
    "    relevant_ptkb_statements = sorted(relevant_ptkb_statements, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    return relevant_ptkb_statements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_response(conversation_history_for_model, relevant_ptkbs, reranked_passages, searcher: LuceneSearcher, num_passages: int, summarizer, tokenizer, current_utterance, pre_reranking=False):\n",
    "\n",
    "    \n",
    "    # split the retrieved documents into groups of num_passages for generating responses\n",
    "    top_docs_for_generating_response = reranked_passages[:num_passages]\n",
    "    \n",
    "    # extract passages from the search results\n",
    "    top_passages = [json.loads(searcher.doc(hit.docid).raw())['contents'] for hit in top_docs_for_generating_response]\n",
    "    \n",
    "\n",
    "    \n",
    "    # join all passages into a single string / cap at 300 words\n",
    "    text = join_and_cap_passages(top_passages, max_words=300)\n",
    "    \n",
    "    ptkb_statements_string = ' '.join([entry['statement'] for entry in relevant_ptkbs])\n",
    "\n",
    "    \n",
    "    llama_user_inputs = f\"\"\"{current_utterance}\"\"\"\n",
    "    \n",
    "        \n",
    "    if pre_reranking == True:\n",
    "        llama_reponse = \"Pre-reranking. Not needed.\" \n",
    "    \n",
    "    else:\n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write('\\nIn:\\n') \n",
    "            f.write('```\\n') \n",
    "            f.write(f'{llama_user_inputs}\\n')        \n",
    "            f.write('```\\n') \n",
    "        \n",
    "        \n",
    "        system_message_content=f\"\"\"\n",
    "                You are an Conversational Assistant part of InfoRetCo, a chat service company. You are currently having a conversation with a loyal customer. Over this customer's time with the company, we have gathered the following information about them: \"{ptkb_statements_string}\".\n",
    "                \n",
    "                We have also gathered the following Answer Provenance Passages (APP) for response generation:\\n{text}\n",
    "                \n",
    "                # Instructions\n",
    "                \n",
    "                // You must complete the conversation below using ONLY the provided Answer Provenance Passages (APP):\n",
    "                // 1. Your reponse must be a maximum of 300 words. I REPEAT: DO NOT EXCEED THE 300 WORD LIMIT.\n",
    "                // 2. Respond without adding, infering, or assuming any details outside the provided provenance passages. I REPEAT: Strictly adhere to the exact information given in the provenance passagess without introducing any new elements or context. \n",
    "                // 3. Your reponse must not cite the provided provenance passages.\n",
    "                // 4. You must provide a single text string. There must not be any additional text surrounding the response.\n",
    "                // 5. Your response must begin with \"Assistant:  ...\"\n",
    "\n",
    "                The Conversation History Context is as follows:{conversation_history_for_model}\n",
    "            \"\"\"\n",
    "        \n",
    "        # get response\n",
    "        llama_reponse = use_llama(\n",
    "            model=summarizer,\n",
    "            tokenizer=tokenizer,\n",
    "            system_message_content=system_message_content,\n",
    "            user_message_content=llama_user_inputs,\n",
    "        )\n",
    "    \n",
    "        llama_reponse = llama_reponse.replace('Assistant: ', '')\n",
    "    \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write('\\n## Prompt:\\n')\n",
    "            f.write('```')\n",
    "            f.write(f'\\n{system_message_content}\\n')\n",
    "            f.write('```\\n')            \n",
    "            f.write('\\nOut:\\n')\n",
    "            f.write('```')\n",
    "            f.write(f'\\n{textwrap.fill(llama_reponse, width=100)}\\n')\n",
    "            f.write('```\\n')\n",
    "    \n",
    "    return [llama_reponse], [top_docs_for_generating_response] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_llama(ptkb, turn, previous_turn, conversation_history, ptkb_qrels, query_id, skip_turns_without_qrels, expected_qrel_passages, model=None, tokenizer=None):\n",
    "    \n",
    "    # variables\n",
    "    utterance = turn['utterance']\n",
    "    \n",
    "    # if it's the first turn\n",
    "    if previous_turn != '':\n",
    "        previous_response = previous_turn['response']\n",
    "        \n",
    "    # init variables if non-first term\n",
    "    previous_response_summary = \"\"\n",
    "    conversation_history_for_model = \"\"\n",
    "    conversation_history_for_model_2 = \"\"\n",
    "    \n",
    "    \n",
    "    # Conversation history management\n",
    "    #----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #################################\n",
    "    # Previous response summarization\n",
    "    #################################\n",
    "    \n",
    "\n",
    "    # no assistant response during the first round\n",
    "    if previous_turn != \"\":\n",
    "        \n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\n## Response summarization model\\n\")\n",
    "            f.write(F\"{'-'*100}\\n\")\n",
    "            f.write(f\"\\nIn:\")\n",
    "            f.write(f\"\\n```\\n\")\n",
    "            f.write(f\"{previous_response}\\n\")\n",
    "            f.write(f\"```\\n\")\n",
    "        \n",
    "        \n",
    "        if len(previous_response) < 150: # only summarize with Llama if previous response is less than 150 chars\n",
    "            previous_response_summary = previous_response\n",
    "        else:\n",
    "        \n",
    "            \n",
    "            previous_response_summary_user_message_content = f\"\"\"{previous_response}\\nThe 150 character response is:\"\"\"\n",
    "                \n",
    "            previous_response_summary = use_llama(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                system_message_content=\"\"\"\n",
    "                    \n",
    "                    You are an Summarization Robot part of a broader Information Retrieval system.\n",
    "                    \n",
    "                    # Instructions\n",
    "                    \n",
    "                    // You will be provided with a text input for which you need to generate a text output and abide to the following policy:\n",
    "                    // 1. Provide a summary the text input of a 150 character maximum of the passage. I REPEAT: DO NOT EXCEED THE 150 CHARACTER LIMIT.\n",
    "                    // 2. Paying particular attention, but not exclusively, to any names, topics, and themes that will be useful to recall in the future. \n",
    "                    // 3. Respond without adding, infering, or assuming any details outside the provided text. \n",
    "                    // 4. I REPEAT: Strictly adhere to the exact information given in the passage without introducing any new elements or context. \n",
    "                    // 5. YOU DO NOT HELP THE USER, YOU PROVIDE THE REQUEST RESPONSE AND NOTHING ELSE. You provide only the response without any introductory or concluding statements or labels. I REPEAT: YOU MUST NOT ANWER THE USER'S QUESTION.\n",
    "                    \"\"\",\n",
    "                user_message_content=previous_response_summary_user_message_content,\n",
    "                \n",
    "                )\n",
    "            \n",
    "        \n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\nOut:\")\n",
    "            f.write(f\"\\n```\\n\")\n",
    "            f.write(f\"{previous_response_summary}\\n\")\n",
    "            f.write(f\"```\\n\")\n",
    "        \n",
    "        \n",
    "        # declutter the conversation history\n",
    "        \n",
    "        # split the conversation history into lines\n",
    "        lines = conversation_history.strip().split('\\n')\n",
    "\n",
    "        # check if there are more than 5 lines\n",
    "        if len(lines) > 5:\n",
    "            # keep only the last 5 lines\n",
    "            lines = lines[-5:]\n",
    "\n",
    "        # join the lines back into a string\n",
    "        conversation_history = \"\\n\".join(lines)\n",
    "        conversation_history = f'\\n{conversation_history}'\n",
    "                \n",
    "        ########## add previous response to conversation history to use in this turn        \n",
    "        conversation_history_for_model = f\"{conversation_history}\\n\\n- **Latest Assistant Reply**: {previous_response}\"\n",
    "        conversation_history_for_model_2 = f\"{conversation_history}\\n- Assistant: {previous_response}\"\n",
    "        conversation_history = f\"{conversation_history}\\n- Assistant: {previous_response_summary}\"\n",
    "        \n",
    "\n",
    "    # skip based on settings\n",
    "    if skip_turns_without_qrels == True and not expected_qrel_passages:\n",
    "        \n",
    "        query_list=\"\"\n",
    "        reranking_list=\"\"\n",
    "        relevant_ptkb_statements=\"\"\n",
    "        ptkb_query_weights=\"\"\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        \n",
    "        \n",
    "                    \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            # true ptkbs\n",
    "            f.write(f\"\\n\\n\\nPassage Ranking Task:\\n\")\n",
    "            f.write(f\"{'#'*100}\")\n",
    "        \n",
    "        \n",
    "\n",
    "        # PTKB Ranking\n",
    "        #----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        #################################\n",
    "        # PTKB Ranking\n",
    "        #################################\n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            # true ptkbs\n",
    "            f.write(f\"\\nPTKB Ranking Task:\\n\")\n",
    "            f.write(f\"{'#'*100}\")\n",
    "            f.write('\\n\\n### True PTKBs according to the qrel:\\n')\n",
    "            f.write(f\"\\n{get_true_ptkbs(ptkb_qrels=ptkb_qrels, conversation_id=query_id)}\\n\")\n",
    "        \n",
    "        \n",
    "        llama_ptkb_ranker_query = f\"\"\"\\n**Conversation History Context:**\\n{conversation_history_for_model}\\n\\n- **Latest User Reply:** {utterance}\"\"\"\n",
    "        \n",
    "        relevant_ptkb_statements = llama_ptkb_ranker(\n",
    "                    # Query is the combined context and utterance\n",
    "                    query=llama_ptkb_ranker_query,\n",
    "                    ptkb=ptkb,                        # pTKB data source\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "        )\n",
    "        \n",
    "        #ptkb_statements_string = ' '.join([entry['statement'] for entry in relevant_ptkb_statements[:3]]) # just the top 3\n",
    "        ptkb_statements_string_comma = ', '.join([entry['statement'] for entry in relevant_ptkb_statements]) # just the top 3\n",
    "        #ptkb_statements_string_full = ' '.join([entry['statement'] for entry in relevant_ptkb_statements]) # full\n",
    "\n",
    "        relevant_ptkb_statements_loop = relevant_ptkb_statements[:3]\n",
    "            \n",
    "        # get weighths\n",
    "        ptkb_query_weights = []\n",
    "\n",
    "        for entry in relevant_ptkb_statements_loop:\n",
    "            ptkb_score = entry['score'] \n",
    "\n",
    "            ptkb_query_weights.append(ptkb_score)\n",
    "        #ptkb_query_weights.insert(0, 1)  # Adds 1 to the start of the list for the original query, the rest for the PTKB specific\n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\n## Llama PTKB Ranking\\n\")\n",
    "            f.write(F\"{'-'*100}\\n\")\n",
    "            f.write(f\"\\nIn:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{llama_ptkb_ranker_query}\\n\")\n",
    "            f.write(f\"```\\n\")            \n",
    "            f.write(f\"\\nOut:\\n\")\n",
    "            for i, item in enumerate(relevant_ptkb_statements, 1):\n",
    "                f.write(f\"{i}. Id: {item['id']}. Score: {item['score']}. Statement: {item['statement']}\\n\")\n",
    "        \n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            # true ptkbs\n",
    "            f.write(f\"\\n\\nPTKB Query Weights:\\n\\n\")\n",
    "            f.write(f\"{ptkb_query_weights}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Query Generation\n",
    "        #----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\n\\nQuery Comprehension:\\n\")\n",
    "            f.write(f\"{'#'*100}\")\n",
    "            f.write(f\"\\n\\n--> Expected comprehension <--\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{turn['response']}\\n\")        \n",
    "            f.write(f\"```\\n\")\n",
    "        \n",
    "        \n",
    "        #################################\n",
    "        # Short Passage Query\n",
    "        #################################\n",
    "\n",
    "        short_passquery_user_message_content = f\"\"\"{utterance} I REPEAT: {utterance}\"\"\"\n",
    "            \n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\n## Generate short answer\\n\")\n",
    "            f.write(F\"{'-'*100}\\n\")\n",
    "            f.write(f\"\\nIn:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{short_passquery_user_message_content}\\n\")\n",
    "            f.write(f\"```\\n\")\n",
    "        \n",
    "        system_message_content=f\"\"\"\n",
    "            You are an Conversational Assistant part of InfoRetCo, a chat service company. You are currently having a conversation with a loyal customer. Over this customer's time with the company, we have gathered the following information about them: \"{ptkb_statements_string_comma}\".\n",
    "\n",
    "            # Instructions\n",
    "            \n",
    "            1. Continue the conversation by responding to the user\n",
    "            2. Your response must begin with \"Assistant: ...\"\n",
    "            3. The response must be exactly 5 full sentences long.\n",
    "            4. You are not allowed to ask follow up questions to the user. I REPEAT: You are not allowed to ask follow up questions to the user.\n",
    "            \n",
    "            \n",
    "            The Conversation History Context is as follows:{conversation_history_for_model_2}\n",
    "            \"\"\"\n",
    "\n",
    "        short_passquery_text = use_llama(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            system_message_content=system_message_content,\n",
    "            user_message_content=short_passquery_user_message_content,\n",
    "            \n",
    "            ) \n",
    "        \n",
    "        # clean\n",
    "        short_passquery_text = short_passquery_text.replace(\"Assistant: \", \"\")\n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            #f.write(f\"\\n{'#'*100}\\n\")\n",
    "            f.write(f\"\\nOut:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{system_message_content}\\n\")\n",
    "            f.write(f\"```\")            \n",
    "            f.write(f\"\\nOut:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{short_passquery_text}\\n\")\n",
    "            f.write(f\"```\")\n",
    "\n",
    "        \n",
    "        #################################\n",
    "        # Long Passage Query\n",
    "        #################################\n",
    "\n",
    "        long_passquery_user_message_content = f\"\"\"{utterance} I REPEAT: {utterance}\"\"\"            \n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\n## Generate Article\\n\")\n",
    "            f.write(F\"{'-'*100}\\n\")\n",
    "            f.write(f\"\\nIn:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{long_passquery_user_message_content}\\n\")\n",
    "            f.write(f\"```\\n\")\n",
    "        \n",
    "        system_message_content=f\"\"\"\n",
    "            You are a Conversational Assistant part of InfoRetCo, a chat service company. You are currently having a conversation with a loyal customer. Over this customer's time with the company, we have gathered the following information about them: \"{ptkb_statements_string_comma}\".\n",
    "\n",
    "            # Instructions\n",
    "            \n",
    "            1. Please generate a 10 sentence article the customer can read to answer their question. I REPEAT: 10 sentences.\n",
    "            2. The writing style must be Formal and Informative. It must presents information in a factual, concise, and authoritative manner, referencing sources and providing specific details. It uses precise language, making it suitable for educational or professional contexts.\n",
    "            2. Your response must begin with \"Article: ...\"\n",
    "            3. You are not allowed to ask follow up questions to the user. I REPEAT: You are not allowed to ask follow up questions to the user.\n",
    "                        \n",
    "            The Conversation History Context is as follows:{conversation_history_for_model_2}\n",
    "                        \n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "        long_passquery_text = use_llama(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            system_message_content=system_message_content,\n",
    "            user_message_content=long_passquery_user_message_content,\n",
    "            \n",
    "            ) \n",
    "        \n",
    "        # clean\n",
    "        long_passquery_text = long_passquery_text.replace(\"Article: \", \"\")\n",
    "        \n",
    "        # remove all line breaks\n",
    "        long_passquery_text = long_passquery_text.replace(\"\\n\", \" \")\n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\nPrompt:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{system_message_content}\\n\")\n",
    "            f.write(f\"```\")            \n",
    "            f.write(f\"\\nOut:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f'\\n{textwrap.fill(long_passquery_text, width=100)}\\n')\n",
    "            f.write(f\"```\")\n",
    "\n",
    "        \n",
    "        query_list = [long_passquery_text, short_passquery_text]\n",
    "        reranking_list = [long_passquery_text, short_passquery_text]\n",
    "\n",
    "\n",
    "        ptkb_query_weights = [1, 1]\n",
    "    \n",
    "    \n",
    "    # update current utterance to conversation history\n",
    "    conversation_history = f\"{conversation_history}\\n- User: {turn['utterance']}\"\n",
    "\n",
    "\n",
    "    return query_list, reranking_list, conversation_history, conversation_history_for_model_2, relevant_ptkb_statements, ptkb_query_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# RUN SETTINGS\n",
    "########################\n",
    "\n",
    "# paths\n",
    "topic_filename = '2024_test_topics.json'\n",
    "run_name = 'main_infosense_llama_short_long_qrs'\n",
    "passage_qrels_filename = 'no_qrel.txt' # '2023-qrels.all-turns.txt' or set to no_qrel.txt to run without qrels. 2023:\n",
    "ptkb_qrels_filename = 'no_qrel.txt'         # '2023-ptkb-qrels.txt' or set to no_qrel.txt.  2023:\n",
    "llama_model_choice = 'Meta-Llama-3.1-8B-Instruct' # 'Meta-Llama-3.1-8B-Instruct', 'Meta-Llama-3-70B-Instruct', 'Meta-Llama-3-8B-Instruct'\n",
    "reranker_mode_choice = ['msmarco-distilbert-base-v4', 'all-MiniLM-L12-v2'] # SentenceTransformers: 'msmarco-distilbert-base-v4', 'msmarco-distilbert-base-tas-b', 'multi-qa-mpnet-base-cos-v1', 'all-mpnet-base-v2', 'paraphrase-mpnet-base-v2',  'all-MiniLM-L12-v2'\n",
    "\n",
    "\n",
    "\n",
    "# variables\n",
    "num_docs        = 5000  # number of documents to retrieve\n",
    "searcher_model = 'bm25'\n",
    "num_response    = 1  # number of responses to generate\n",
    "num_passages    = 3  # number of passages to use to generate a responses\n",
    "cuda_device_num = 1\n",
    "use_cuda        = True\n",
    "\n",
    "ptkb_ranker     = 'llama'\n",
    "query_rewriter  = 'llama'\n",
    "use_subtree_only = None      # None or a list with specific subtrees, e.g. 2023: ['9-1', '9-2', '10-1']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "skip_turns_without_qrels = False\n",
    "\n",
    "########################\n",
    "# VARIABLE INITIALIZATION\n",
    "########################\n",
    "\n",
    "run_start_timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "# create directory if non exists\n",
    "directory = f'./output/{run_start_timestamp}/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "index_path = settings.INDEX_PATH\n",
    "qrels_filepath = settings.QRELS_PATH\n",
    "models_path = f'{settings.MODELS_PATH}'\n",
    "topic_path = f'{settings.TOPICS_PATH}/{topic_filename}'\n",
    "passage_qrels_filepath = f'{qrels_filepath}/{passage_qrels_filename}'\n",
    "ptkb_qrels_filepath = f'{qrels_filepath}/{ptkb_qrels_filename}'\n",
    "output_filename = f'./output/{run_start_timestamp}/{run_name}.json'\n",
    "verbose_output_filename = f'./output/{run_start_timestamp}/{run_name}_verbose.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the specified JSON file\n",
    "print(f'Loading data from {topic_filename}')\n",
    "with open(topic_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "print('[Done].')\n",
    "\n",
    "# subset if a specific subtree is chosen\n",
    "if use_subtree_only is not None:\n",
    "    data = [entry for entry in data if entry['number'] in use_subtree_only]\n",
    "    print(f'subtree chosen: {use_subtree_only}')\n",
    "\n",
    "# Further filter the turns by specific turn_id\n",
    "#specific_turn_id = [3]\n",
    "#for entry in data:\n",
    "#    entry['turns'] = [turn for turn in entry['turns'] if turn['turn_id'] in specific_turn_id]\n",
    "\n",
    "\n",
    "# uncomment to see preview\n",
    "# Limit the number of lines to be printed\n",
    "#n = 2\n",
    "#for item in data[:n]:\n",
    "#    print(json.dumps(item, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the specified JSON file\n",
    "print(f'Loading data from {ptkb_qrels_filename}')\n",
    "with open(ptkb_qrels_filepath, 'r') as f:\n",
    "    ptkb_qrels = f.readlines()\n",
    "print('[Done].')\n",
    "\n",
    "# uncomment to see preview\n",
    "#ptkb_qrels[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the specified JSON file\n",
    "print(f'Loading data from {passage_qrels_filename}')\n",
    "with open(passage_qrels_filepath, 'r') as f:\n",
    "    passage_qrels = f.readlines()\n",
    "print('[Done].')\n",
    "\n",
    "# uncomment to see preview\n",
    "#passage_qrels[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beginning timestamp\n",
    "beginning_timestamp = datetime.now()\n",
    "\n",
    "\n",
    "# set the CUDA device if available and required\n",
    "cuda_device = 'cuda:' + str(cuda_device_num)\n",
    "device = torch.device(cuda_device if torch.cuda.is_available() and use_cuda else 'cpu')\n",
    "\n",
    "\n",
    "# load models into a list\n",
    "reranker_model = []\n",
    "for model_name in reranker_mode_choice:\n",
    "    model_path = f'{models_path}/{model_name}'\n",
    "    model = SentenceTransformer(model_path)\n",
    "    reranker_model.append(model)\n",
    "\n",
    "\n",
    "# define the local path to the model directory\n",
    "local_path = f\"{models_path}/{llama_model_choice}/\"\n",
    "\n",
    "# load the tokenizer from the specified local path\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(local_path, local_files_only=True)\n",
    "\n",
    "# load the model from the specified local path\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",  # comment out if not enough GPU resources\n",
    "    local_files_only=True,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# initialize the searcher with the specified index\n",
    "searcher = LuceneSearcher(index_dir=index_path)\n",
    "\n",
    "# BM25 params\n",
    "k1 = 1.2 \n",
    "b = 0.75 \n",
    "searcher.set_bm25(k1=k1, b=b)\n",
    "\n",
    "\n",
    "\n",
    "# save info for tracking system progress\n",
    "with open(verbose_output_filename, 'a') as f:\n",
    "    f.write(\n",
    "        f'Beginning Timestamp: {beginning_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")}\\n\\n')\n",
    "    f.write(f'Params:\\n')\n",
    "    f.write(f'Using device: {device}\\n')\n",
    "    f.write(f'Run Type ==> automatic\\n')\n",
    "    f.write(f'Number of responses to generate ==> {num_response}\\n')\n",
    "    f.write(\n",
    "        f'Number of passages to use for response generation ==> {num_passages}\\n')\n",
    "    f.write(f'PTKB ranking function ==> {ptkb_ranker}\\n')\n",
    "    f.write(f'Retrieval Model ==> {searcher_model}\\n')\n",
    "    f.write(f'Reranker Model ==> {reranker_mode_choice}\\n')\n",
    "    f.write(f\"\\n{'#'*100}\\n\\n\")\n",
    "\n",
    "\n",
    "# open the result JSON file\n",
    "with open(output_filename, 'a') as f:\n",
    "    f.write(\"{\\n\")\n",
    "    f.write(f\"\"\"    \"run_name\": \"{run_name}\",\\n\"\"\")\n",
    "    f.write(f\"\"\"    \"run_type\": \"automatic\",\\n\"\"\")\n",
    "    f.write(f\"\"\"    \"eval_response\": true,\\n\"\"\")\n",
    "    f.write(f\"\"\"    \"turns\": [\\n\"\"\")\n",
    "\n",
    "\n",
    "# initialize variables\n",
    "num_turns = 0\n",
    "num_subtrees = len(data)\n",
    "total_found_passages = 0\n",
    "total_total_passages_expected = 0\n",
    "\n",
    "# df for tracking results\n",
    "full_results_table = []\n",
    "\n",
    "\n",
    "for idx, d in enumerate(data):\n",
    "    \n",
    "\n",
    "    print(\n",
    "        f'========PROCESSING CONVERSATION-{idx + 1} OF {num_subtrees}==============')\n",
    "\n",
    "    # save all the prints to a text file for tracking system progress\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write(\n",
    "            f'\\n========PROCESSING CONVERSATION-{idx + 1} OF {num_subtrees}==============\\n')\n",
    "\n",
    "    number = str(d['number']) # convert to string to handle 2024 topics\n",
    "    turns = d['turns']\n",
    "    ptkb = d['ptkb']\n",
    "\n",
    "\n",
    "    # initialize variables that need to reset at every conversation\n",
    "    conversation_history = \"\"\n",
    "    previous_turn = \"\"\n",
    "    turns_in_subtree = len(turns)\n",
    "    conversation_found_passages = 0\n",
    "    conversation_total_passages_expected = 0\n",
    "\n",
    "    # update the total number of turns\n",
    "    num_turns += len(turns)\n",
    "\n",
    "\n",
    "    # check condition if no qrels for entire run\n",
    "    conv_has_qrels = has_qrels_for_conversation(passage_qrels, number)\n",
    "    if skip_turns_without_qrels == True and not conv_has_qrels: \n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n### Skipping {number} for no qrels in entire conversation:\")\n",
    "            \n",
    "        # remove last ',\\n' comma from jason\n",
    "        with open(output_filename, 'r') as f:\n",
    "            content = f.read()\n",
    "        if content.endswith(\",\\n\"):\n",
    "            content = content[:-2]        \n",
    "        with open(output_filename, 'w') as f:\n",
    "            f.write(content)\n",
    "\n",
    "        continue # go to next conversation\n",
    "    \n",
    "    \n",
    "    \n",
    "    # save all the prints to a text file for tracking system progress\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write('\\nSTART CONVERSATION\\n')\n",
    "\n",
    "    # process each turn in the conversation\n",
    "    for turn in tqdm(turns, total=len(turns)):\n",
    "        \n",
    "        \n",
    "        # turn level vars\n",
    "        turn_id = turn['turn_id']\n",
    "        query_id = number + '_' + str(turn_id)\n",
    "        \n",
    "        turn_found_passages = 0\n",
    "        turn_total_passages_expected = 0\n",
    "\n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n{'#'*100}\\n\")\n",
    "            f.write(f\"topic-subtree: {number}\\n\")\n",
    "            f.write(f\"turn: {turn['turn_id']} of {turns_in_subtree}\\n\")\n",
    "            f.write(f\"{'#'*100}\\n\")\n",
    "\n",
    "        \n",
    "        # save all the prints to a text file for tracking system progress\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            # users utters\n",
    "            f.write(f\"\\n### User utters:\")\n",
    "            f.write(f\"\\n```\")\n",
    "            f.write(f\"\\n{textwrap.fill(turn['utterance'], width=100)}\\n\")\n",
    "            f.write(f\"```\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        # see if you got all the documents in the qrels ...\n",
    "        \n",
    "        # get qrels\n",
    "        expected_qrel_passages = extract_relevant_passages(passage_qrels=passage_qrels, conversation_id=query_id, verbose_output_filename=verbose_output_filename)\n",
    "       \n",
    "        ##############\n",
    "        # generate query\n",
    "        #############\n",
    "        \n",
    "        query_list, reranking_list, conversation_history, conversation_history_for_model, relevant_ptkb_statements, ptkb_query_weights = get_query_llama(\n",
    "            ptkb=ptkb,\n",
    "            turn=turn,\n",
    "            model=llama_model,\n",
    "            tokenizer=llama_tokenizer,\n",
    "            conversation_history=conversation_history,\n",
    "            ptkb_qrels=ptkb_qrels,\n",
    "            query_id=query_id,\n",
    "            previous_turn=previous_turn,\n",
    "            skip_turns_without_qrels=skip_turns_without_qrels,\n",
    "            expected_qrel_passages=expected_qrel_passages,\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "        # skip based on settings\n",
    "        if skip_turns_without_qrels == True and not expected_qrel_passages:\n",
    "            \n",
    "            # save all the prints to a text file for tracking system progress\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f\"\\n{'#'*100}\\n\")\n",
    "                f.write(f\"This turn has no qrels. Skipping the search task...\\n\")\n",
    "                f.write(f\"{'#'*100}\\n\")\n",
    "                \n",
    "            # Remove the last character in the file (the comma)\n",
    "            if turns_in_subtree == turn_id and (idx + 1) == num_subtrees:\n",
    "                with open(output_filename, 'r') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                # Check if the content ends with \",\\n\"\n",
    "                if content.endswith(\",\\n\"):\n",
    "                    # Remove the last 2 characters (\",\\n\")\n",
    "                    content = content[:-2]\n",
    "\n",
    "                # Open the file in write mode to overwrite the content\n",
    "                with open(output_filename, 'w') as f:\n",
    "                    f.write(content)\n",
    "\n",
    "            \n",
    "            previous_turn = turn\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Separate the run in verbose output\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                \n",
    "                # ending timestamps\n",
    "                midrun_timestamp = datetime.now()\n",
    "                total_time = midrun_timestamp - beginning_timestamp\n",
    "                f.write(f'\\nTimestamp: {midrun_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "                f.write(f'Time Elapsed: {total_time}\\n')        \n",
    "                f.write(F\"\\nNext turn ...\\n\\n\\n\")\n",
    "                f.write(F\"{'|'*100}\\n\")\n",
    "                f.write(F\"{'|'*100}\\n\")\n",
    "                f.write(F\"{'|'*100}\\n\\n\")\n",
    "                \n",
    "            continue # go to next conversation\n",
    "        \n",
    "        else:   \n",
    "            \n",
    "            #########################\n",
    "            # quick retrieve documents\n",
    "            ##########################\n",
    "\n",
    "            # save all the prints to a text file for tracking system progress\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f\"\\n\\nRetrieval Task\\n\")\n",
    "                f.write(F\"{'#'*100}\\n\")\n",
    "\n",
    "            preliminary_hits, query_source_counts, query_source_docs = combine_hits(query_list, query_id, num_docs, searcher, verbose_output_filename)\n",
    "\n",
    "            # save all the prints to a text file for tracking system progress\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f'\\n{len(preliminary_hits):,} documents retrieved.\\n')\n",
    "\n",
    "            ######################\n",
    "            # check success\n",
    "            ######################\n",
    "\n",
    "            if not expected_qrel_passages:  # if empty list\n",
    "                # save all the prints to a text file for tracking system progress\n",
    "                with open(verbose_output_filename, 'a') as f:\n",
    "                    f.write(f'\\nNo passage qrels for turn {query_id}. Moving on ...\\n')\n",
    "            else:\n",
    "                \n",
    "                # check retrieval success of original\n",
    "                turn_found_passages, turn_total_passages_expected = check_quick_retrieval_success(preliminary_hits, expected_qrel_passages, query_source_counts, query_source_docs, verbose_output_filename)\n",
    "            \n",
    "                \n",
    "             \n",
    "                \n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f\"\\n\\nReranking Task\\n\")\n",
    "                f.write(F\"{'#'*100}\\n\")\n",
    "                f.write(f'\\n## Reranking the documents...\\n')\n",
    "\n",
    "\n",
    "            reranked_passages = passage_neural_retrieval(\n",
    "                preliminary_hits=preliminary_hits, \n",
    "                reranking_list=reranking_list, \n",
    "                verbose_output_filename=verbose_output_filename, \n",
    "                model=reranker_model, \n",
    "                query_weights=ptkb_query_weights, \n",
    "                top_k=1000,\n",
    "                )\n",
    "            \n",
    "            # save all the prints to a text file for tracking system progress\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f'\\n## Reranking done.\\n')\n",
    "                f.write(f\"\\n\\nResponse Generation Task\\n\")\n",
    "                f.write(F\"{'#'*100}\\n\")\n",
    "                f.write(f'\\n## Generating the response...\\n')\n",
    "\n",
    "            # generate reponses pre-reranking\n",
    "            sorted_responses_prereranking, sorted_responses_provenance_prereranking = generate_top_response(\n",
    "                conversation_history_for_model=conversation_history_for_model,\n",
    "                relevant_ptkbs=relevant_ptkb_statements,\n",
    "                reranked_passages=preliminary_hits,\n",
    "                searcher=searcher,\n",
    "                num_passages=num_passages,\n",
    "                summarizer=llama_model,\n",
    "                tokenizer=llama_tokenizer,\n",
    "                current_utterance=turn['utterance'],\n",
    "                pre_reranking=True,\n",
    "            )\n",
    "            # generate reponses\n",
    "            sorted_responses, sorted_responses_provenance = generate_top_response(\n",
    "                conversation_history_for_model=conversation_history_for_model,\n",
    "                relevant_ptkbs=relevant_ptkb_statements,\n",
    "                reranked_passages=reranked_passages,\n",
    "                searcher=searcher,\n",
    "                num_passages=num_passages,\n",
    "                summarizer=llama_model,\n",
    "                current_utterance=turn['utterance'],\n",
    "                tokenizer=llama_tokenizer,\n",
    "            )\n",
    "            \n",
    "            # Calculate current turn performance\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f\"\\n\\nExpected response\\n\")\n",
    "                f.write('```\\n')\n",
    "                f.write(F\"{turn['response']}\\n\")\n",
    "                f.write('```\\n')\n",
    "\n",
    "            #########################\n",
    "            # performance measurement\n",
    "            #########################\n",
    "\n",
    "            # NOTE: this pre-rank variable is just for ranking performance measurement,\n",
    "            # hence the sorted responses and their provenenance correspond to the post reranking.\n",
    "            # Don't use this variable for anything else as the it will lead to wrong results\n",
    "            turn_json_pre_rerank = prepare_output_for_json(\n",
    "                turn_id=query_id,\n",
    "                sorted_responses=sorted_responses_prereranking,\n",
    "                sorted_responses_provenance=sorted_responses_provenance_prereranking,\n",
    "                reranked_passages=preliminary_hits,            # Only this matters here\n",
    "                searcher=searcher,\n",
    "                relevant_ptkbs=relevant_ptkb_statements\n",
    "            )\n",
    "\n",
    "            # add to the JSON output\n",
    "            turn_json_post_rerank = prepare_output_for_json(\n",
    "                turn_id=query_id,                           \n",
    "                sorted_responses=sorted_responses,          \n",
    "                sorted_responses_provenance=sorted_responses_provenance,\n",
    "                reranked_passages=reranked_passages,        \n",
    "                searcher=searcher,                          \n",
    "                relevant_ptkbs=relevant_ptkb_statements\n",
    "            )\n",
    "\n",
    "            # Calculate current turn performance\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f\"\\n\\nReranking task performance measurement\\n\")\n",
    "                f.write(F\"{'#'*100}\\n\")\n",
    "                # f.write(f'\\n### Calculating the current turn reranking task performance ...\\n')\n",
    "\n",
    "            if not expected_qrel_passages:  # if empty list\n",
    "                with open(verbose_output_filename, 'a') as f:\n",
    "                    f.write(f'\\nNo passage qrels for turn {query_id}. Moving on ...\\n')\n",
    "\n",
    "            else:\n",
    "\n",
    "                turn_result_evaluations_pre = measure_intrarun_ranking_performance(turn_json_pre_rerank, run_name, output_filename, passage_qrels_filename)\n",
    "                turn_result_evaluations_post = measure_intrarun_ranking_performance(turn_json_post_rerank, run_name, output_filename, passage_qrels_filename)\n",
    "\n",
    "                combined_metrics = combine_performance_metrics(turn_result_evaluations_pre, turn_result_evaluations_post)\n",
    "\n",
    "                # Save to output file\n",
    "                with open(verbose_output_filename, 'a') as f:\n",
    "                    f.write(f'\\n## Combined Performance Metrics\\n')\n",
    "                    f.write(F\"{'-'*100}\\n\\n\")\n",
    "                    f.write(combined_metrics)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Update variables\n",
    "            previous_turn = turn\n",
    "            conversation_found_passages += turn_found_passages\n",
    "            conversation_total_passages_expected += turn_total_passages_expected\n",
    "\n",
    "            \n",
    "            # save all the prints to a text file for tracking system progress\n",
    "            with open(verbose_output_filename, 'a') as f:\n",
    "                f.write(f\"\\n\\nHousekeeping\\n\")\n",
    "                f.write(F\"{'#'*100}\\n\")\n",
    "                f.write(f'\\nUpdating the run JSON file ...\\n')\n",
    "\n",
    "            \n",
    "            # Add 8 spaces outside the `with open` line\n",
    "            json_str = json.dumps(turn_json_post_rerank, indent=4)\n",
    "            indented_json_str = '\\n'.join('        ' + line for line in json_str.splitlines())\n",
    "            \n",
    "            \n",
    "            # Write turn to JSON\n",
    "            with open(output_filename, 'a') as f:\n",
    "                # Dont include the comma if last turn of the last subtree\n",
    "                if turns_in_subtree == turn_id and (idx + 1) == num_subtrees:\n",
    "                    f.write(indented_json_str + '\\n')\n",
    "                else:\n",
    "                    f.write(indented_json_str + ',\\n')\n",
    "\n",
    "        # Separate the run in verbose output\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            \n",
    "            # ending timestamps\n",
    "            midrun_timestamp = datetime.now()\n",
    "            total_time = midrun_timestamp - beginning_timestamp\n",
    "            f.write(f'\\nTimestamp: {midrun_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "            f.write(f'Time Elapsed: {total_time}\\n')        \n",
    "            f.write(F\"\\nNext turn ...\\n\\n\\n\")\n",
    "            f.write(F\"{'|'*100}\\n\")\n",
    "            f.write(F\"{'|'*100}\\n\")\n",
    "            f.write(F\"{'|'*100}\\n\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # update conversation level vars\n",
    "    total_found_passages += conversation_found_passages\n",
    "    total_total_passages_expected += conversation_total_passages_expected\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # conversation level reporting\n",
    "    ########################\n",
    "    \n",
    "    if not conv_has_qrels:  # if empty list\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f'\\nNo conversation-level qrels for turn {number}. Moving on ...\\n')\n",
    "\n",
    "    else:\n",
    "    \n",
    "    \n",
    "        \n",
    "        # Separate the run in verbose output\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\nConversation-level performance\\n\")\n",
    "            f.write(F\"{'#'*100}\\n\\n\")\n",
    "            f.write(f'Total correct passages found in conversation: {conversation_found_passages}\\n')\n",
    "            f.write(f'Total correct passages expected  in conversation: {conversation_total_passages_expected}\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # avoid division by zero when no qrels for topic\n",
    "            if conversation_total_passages_expected != 0:\n",
    "                conversation_found_passages_fraction = conversation_found_passages / conversation_total_passages_expected\n",
    "            else:\n",
    "                conversation_found_passages_fraction = 0\n",
    "            \n",
    "            \n",
    "            f.write(f'Fraction found: {conversation_found_passages_fraction:,}\\n\\n')\n",
    "\n",
    "            \n",
    "\n",
    "        # open the json file and format for computing performance\n",
    "        with open(output_filename, 'r') as file:\n",
    "            json_data = file.read()\n",
    "            # find the position of the last closing brace ('}')\n",
    "            last_brace_index = json_data.rfind('}')\n",
    "            json_data = json_data[:last_brace_index]\n",
    "            json_data = json_data + \"}]}\" # complete it\n",
    "            partial_json = json.loads(json_data)\n",
    "\n",
    "\n",
    "        # compute\n",
    "        conversation_turn_json = select_turns_by_prefix(partial_json, number)\n",
    "            \n",
    "        conversation_performance_metrics = measure_intrarun_ranking_performance(conversation_turn_json, run_name, output_filename, passage_qrels_filename, section_type = \"conversation\")\n",
    "\n",
    "            # Save to output file\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f'{conversation_performance_metrics}\\n\\n')\n",
    "            \n",
    "        # tracker table\n",
    "        full_results_evaluations = extract_evaluations(conversation_performance_metrics)\n",
    "            \n",
    "        full_results_table.append(\n",
    "            {\n",
    "                'topic_subtree': number, \n",
    "                'found_passages_fraction': conversation_found_passages_fraction,\n",
    "                'ndcg_3': full_results_evaluations[\"ndcg_cut_3\"], \n",
    "                'ndcg_5': full_results_evaluations[\"ndcg_cut_5\"], \n",
    "                'ndcg': full_results_evaluations[\"ndcg\"], \n",
    "                'p_20': full_results_evaluations[\"P_20\"],\n",
    "                'recall_20': full_results_evaluations[\"recall_20\"], \n",
    "                'map': full_results_evaluations[\"map\"],\n",
    "            })\n",
    "        \n",
    "        \n",
    "        # separate the run in verbose output\n",
    "        with open(verbose_output_filename, 'a') as f:\n",
    "            f.write(f\"\\n\\nPerformance Summary\\n\\n\")\n",
    "            f.write(f'{pd.DataFrame(full_results_table).to_string(index=False)}\\n\\n')\n",
    "\n",
    "        \n",
    "\n",
    "# close the result JSON file\n",
    "with open(output_filename, 'a') as f:\n",
    "    f.write(f\"\"\"    ]\\n\"\"\")\n",
    "    f.write(\"}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "# run level reporting\n",
    "########################\n",
    "\n",
    "if passage_qrels_filename != 'no_qrel.txt':\n",
    "        \n",
    "    # ending timestamps\n",
    "    ending_timestamp = datetime.now()\n",
    "    total_time = ending_timestamp - beginning_timestamp\n",
    "\n",
    "    # Separate run in verbose output\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write(F\"\\nDone\\n\")\n",
    "        f.write(f'Ending Timestamp: {ending_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")}\\n')\n",
    "        f.write(f'Total Time: {total_time}\\n')\n",
    "        \n",
    "    # Separate the run in verbose output\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write(f\"\\n\\nRun-level performance\\n\")\n",
    "        f.write(F\"{'#'*100}\\n\\n\")\n",
    "        f.write(f'Total correct passages found in run: {total_found_passages}\\n')\n",
    "        f.write(f'Total correct passages expected in run: {total_total_passages_expected}\\n')\n",
    "        \n",
    "        if total_total_passages_expected != 0:\n",
    "            total_found_passages_fraction = total_found_passages / total_total_passages_expected\n",
    "        else:\n",
    "            total_found_passages_fraction = 0\n",
    "        \n",
    "        f.write(f'Fraction found: {total_found_passages_fraction:,}\\n')\n",
    "\n",
    "\n",
    "    # Convert passage output in JSON to TRECRun format\n",
    "    run_generate_run(output_filename)\n",
    "\n",
    "\n",
    "    # full results    \n",
    "    evaluations_ndcg_cut_3 = run_trec_eval(passage_qrels_filename, f\"{output_filename.replace('.json', '.json.run')}\", metric_list=['ndcg_cut.3'])\n",
    "    evaluations = run_trec_eval(passage_qrels_filename, f\"{output_filename.replace('.json', '.json.run')}\", metric_list=['ndcg', 'ndcg_cut', 'P', 'recall', 'map'])\n",
    "\n",
    "    evaluations = full_evaluations_join(evaluations_ndcg_cut_3, evaluations)\n",
    "\n",
    "\n",
    "    # Save to verbose output\n",
    "    with open(verbose_output_filename, 'a') as f:\n",
    "        f.write(f'\\n\\nOverall Passage Ranking Task Performance\\n')\n",
    "        f.write(evaluations)\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ikat_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
